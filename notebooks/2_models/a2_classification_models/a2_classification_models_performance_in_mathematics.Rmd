---
title: 'Classification Models for students performance in Mathematics A2'
author: "Erick Calderon-Morales"
date: ' Fall 2021'
due_date: ""
output:
  prettydoc::html_pretty:
    highlight: pygments
    theme: cayman
    toc: yes
    number_sections: no
    toc_depth: 1

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,comment = "", fig.align = 'center',
					  fig.width = 20, fig.height = 15)
options(scipen=999)
```



```{r knitr, include = FALSE}

# Save figures in specific place

knitr::opts_chunk$set(autodep        = TRUE,
                      cache          = FALSE,
                      cache.comments = TRUE,
                      
                      # Include code?
                      echo           = TRUE,
                      
                      error          = FALSE,
                      fig.align      = "center",
                      
                      # Path to where to store pdf single figures
                      fig.path       = paste0("../a2_classification_models/figures_classification_models", "/"),
                      fig.width      = 20,
                      fig.height     = 15,
                      message        = FALSE,
                      warning        = FALSE)
```


```{r cleanup-docs, cache = FALSE,echo = FALSE}

# save a html copy file in a specific place
#doc.files <- c(list.files(pattern = "pdf"),
#               list.files(pattern = "html"),
#               list.files(pattern = "docx"))

#for (file in doc.files) {
#  cambiar nombre
#    file.rename(file, file.path("../../hw1/", file))
#}
```


```{r libaries, message=FALSE, warning=FALSE, cache=FALSE}
# Packages
library(caret)
library(tidyverse)
# For cleaning names
library(janitor)
# Best subset selection 
library(yardstick)
library(kknn)
# For decision tree
library(rpart)
library(partykit)
library(randomForest)
#for dummy coding
library(psych)
library(pROC) 
library(tidyr)
library(randomForest)
library(gbm)
library(flextable)
```

```{r}
# Load data
dataset_math_perform  <- read.csv("../../../data/clean_data_student_math_performance.csv", 
                                      header=TRUE) 
```

```{r}

math_performance  <- 
  dataset_math_perform %>% 
    dplyr::select(-c(g3,X)) %>% 
        
        # Transform variables to numeric
        mutate(g3_binary = factor(g3_binary),
               g2 = as.integer(g2),
               g1 = as.integer(g1),
               absences = as.integer(absences)) %>%
        # Transform chr type to factor
        mutate(across(where(is.character), as.factor))
    
```


```{r}
str(math_performance)
```

# Split data into training and testing
```{r}
set.seed(999)
# slip data into train and test

# Get index
train_index <- sample(1:nrow(math_performance ),
                      (nrow(math_performance )*75)/100)

# Train set
math_performance_train <- math_performance[train_index,]

# Test set
math_performance_test <- math_performance[-train_index,]
```

```{r echo = FALSE}
print(paste0("Size of training dataset: ",
             nrow(math_performance_train)*100/nrow(math_performance), " %"))

print(paste0("Size of testing dataset: ",
             nrow(math_performance_test)*100/nrow(math_performance), " %"))
```
```{r}
# First, we set up the cross validation control
# Setting up the k-fold cross validation k = 10 cross-validation folds.

#Setting the random seed for replication
set.seed(999)

#setting up cross-validation
cvcontrol <- trainControl(method = "repeatedcv", 
                          number = 10,
                          allowParallel = TRUE)
```



# Classification Tree


```{r}
train_tree <- train(g3_binary ~ ., 
                   data = math_performance_train,
                   method = "ctree",
                   trControl = cvcontrol,
                   tuneLength = 5)
```

```{r}
# obtaining class predictions
tree_class_test <-  predict(train_tree,
                            newdata = math_performance_test, 
                            type = "raw")
```


```{r}
descision_tree_stats <- confusionMatrix(math_performance_test$g3_binary,
                                        tree_class_test,positive = "pass" )

decision_table <- 
    rbind(as.data.frame(descision_tree_stats[3]) %>%
            rownames_to_column("var") %>% 
            rename(value = "overall") %>% 
            filter(var %in% c("Accuracy","AccuracyLower","AccuracyUpper")),
            
          as.data.frame(descision_tree_stats[4]) %>% 
            rownames_to_column("var")  %>%
            rename(value = "byClass") %>%
            filter(var %in% c("Sensitivity","Specificity"))) %>%
      
    mutate(model = factor(rep("decision_tree", nrow(.))))
```


# Bagging of ctrees

```{r}
#Using treebag 
train_bagg <- train(g3_binary  ~ ., 
                   data = math_performance_train,
                   method = "treebag",
                   trControl = cvcontrol,
                   importance = TRUE,
                   tuneLength = 5,)

```


```{r}
bagg_class_test <- predict(train_bagg, 
                          newdata = math_performance_test,
                          type="raw")
```


```{r}
bagging_stats <- confusionMatrix(math_performance_test$g3_binary, bagg_class_test,
                                 positive = "pass")

bagging_table <- 
  rbind(as.data.frame(bagging_stats[3]) %>% 
          rownames_to_column("var") %>% 
          rename(value = "overall") %>% 
          filter(var %in% c("Accuracy","AccuracyLower","AccuracyUpper")),
            
        as.data.frame(bagging_stats[4]) %>% 
          rownames_to_column("var")  %>%
          rename(value = "byClass") %>%
          filter(var %in% c("Sensitivity","Specificity"))) %>% 
  mutate(model = factor(rep("bagging_tree", nrow(.))))
```

# Random Forest for classification trees
```{r}
#Using treebag 
train_random_forest <- train(g3_binary  ~ ., 
                             data = math_performance_train,
                             method = "rf",
                             trControl = cvcontrol,
                             importance = TRUE)

```

```{r}
#obtaining class predictions
rf_class_test <- predict(train_random_forest, 
                         newdata = math_performance_test,
                          type="raw")
```


```{r}
random_forest_stats <- confusionMatrix(math_performance_test$g3_binary,rf_class_test,
                positive = "pass" )

rf_table <- 
  rbind(as.data.frame(random_forest_stats[3]) %>% 
        rownames_to_column("var") %>% 
        rename(value = "overall") %>% 
        filter(var %in% c("Accuracy","AccuracyLower","AccuracyUpper")),
          
      as.data.frame(random_forest_stats[4]) %>% 
        rownames_to_column("var")  %>%
        rename(value = "byClass") %>%
        filter(var %in% c("Sensitivity","Specificity"))) %>% 
  mutate(model = factor(rep("random_forest", nrow(.))))
```

# Random Forest with Gradient Boosting

```{r}
train_gbm <- train(g3_binary ~ ., 
                   data = math_performance_train,
                   method="gbm",
                   
                   verbose = F,
                   trControl=cvcontrol)

```


```{r}
#obtaining class predictions
gbm_class_test <-  predict(train_gbm,
                           newdata = math_performance_test,
                           type = "raw",
                           importance = T)
```


```{r}
#computing confusion matrix
random_rorest_gradient_boosting_stats <- confusionMatrix(math_performance_test$g3_binary,
                                                   gbm_class_test,
                                                   positive = "pass" )

rf_gradient_boosting_table <- 
          rbind(as.data.frame(random_rorest_gradient_boosting_stats[3]) %>% 
                  rownames_to_column("var") %>% 
                  rename(value = "overall") %>% 
                  filter(var %in% c("Accuracy","AccuracyLower","AccuracyUpper")),
                    
                as.data.frame(random_rorest_gradient_boosting_stats[4]) %>% 
                  rownames_to_column("var")  %>%
                  rename(value = "byClass") %>%
                  filter(var %in% c("Sensitivity","Specificity"))) %>% 
          mutate(model = factor(rep("random_rorest_gradient_boosting",nrow(.))))
```


# kNN
```{r}
knn_pred_caret <- train(g3_binary ~ .,
                        math_performance_train,
                        method = "knn",
                        preProcess = c("center","scale"))

```

```{r}
knn_predict <- predict(knn_pred_caret, newdata = math_performance_test)
```


```{r}
knn_stats <- confusionMatrix(knn_predict, math_performance_test$g3_binary, 
                positive = "pass")

knn_table <- 
      rbind(as.data.frame(knn_stats[3]) %>% 
              rownames_to_column("var") %>% 
              rename(value = "overall") %>% 
              filter(var %in% c("Accuracy","AccuracyLower","AccuracyUpper")),
          
            as.data.frame(knn_stats[4]) %>% 
              rownames_to_column("var")  %>%
              rename(value = "byClass") %>%
              filter(var %in% c("Sensitivity","Specificity"))) %>% 
      mutate(model = factor(rep("knn", nrow(.))))
```


# Figure 5
```{r fig.width = 7, fig.height=7}
plot(varImp(train_gbm))
```


# Table 5

```{r}
(table_5 <- rbind(decision_table, bagging_table, rf_table,
            rf_gradient_boosting_table, knn_table) %>% 
    pivot_wider(names_from = var, values_from = value) %>% 
  flextable())
  

table_5 <- autofit(table_5)

save_as_image(x = table_5, path = "../a2_classification_models/figures_classification_models/table_5.png")

```


